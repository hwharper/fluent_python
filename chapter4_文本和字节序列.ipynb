{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人类使用文本，计算机使用字节序列。——Esther Nam和Travis Fischer\n",
    "\n",
    "本章主要讨论Unicode字符串、二进制序列，以及在二者之间转换时使用的编码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 字符问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字符：可以理解为Unicode字符。\n",
    "* 码位：字符的标识，可以理解为序号。\n",
    "* 字符的具体表述，取决于所用的编码。\n",
    "\n",
    "> Python3的`str`对象和Python2的`Unicode`对象的元素是Unicode字符，Python2的`str`对象获取的是原始字节序列，但专门的二进制序列提供的功能，有些是Py2的`str`类型不具有的。\n",
    "\n",
    "> `编码`：把码位（str对象对应码位）转换为字节序列（bytes对象）。`解码`：把字节序列转换为码位。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 编码和解码\n",
    "s = 'café'\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'caf\\xc3\\xa9'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = s.encode('utf8') # str对象变为bytes对象，bytes字面量以b开头\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b) # 在UTF-8中，é编码为两个字节，即16位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.decode('utf8') # bytes对象变为str对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 字节概要\n",
    "本节介绍Python内置的两种基本的二进制序列类型：\n",
    "* Python 3引入的不可变的`bytes`类型\n",
    "* Python 2.6添加的可变`bytearray`类型\n",
    "> Python2.6的`bytes`类型只不过是`str`的别称。\n",
    "\n",
    "`bytes`或`bytearray`对象的各个元素是介于0～255（含）之间的整数（即8位，一个字节）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'caf\\xc3\\xa9'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 包含5个字节的bytes和bytesarray对象\n",
    "cafe = bytes('café', encoding='utf8')\n",
    "cafe # 'caf'是可打印字符，直接显示，而‘é’不是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cafe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'c'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cafe[:1] # 二进制序列的切片始终是同一类型的二进制序列，对比之下string[0] == string[:1]为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytearray(b'caf\\xc3\\xa9')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cafe_arr = bytearray(cafe) # bytearray对象没有字面量句法，而是以bytearray()和字节序列字面量参数的形式显示\n",
    "cafe_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytearray(b'\\xa9')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cafe_arr[-1:] # 二进制序列的切片始终是同一类型的二进制序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二进制序列虽然是整数序列，但从其字面量表示法可以看出，内含ASCII文本，比如cafe对应b'caf\\xc3\\xa9'。\n",
    "\n",
    "二进制序列___字面量表示法___中各个字节的值可能会用以下三种方式显示：\n",
    "* 可打印ASCII范围内的字节（从空格到～），使用ASCII字符本身;\n",
    "* 制表符、换行符、回车符和\\对应的字节，使用转义序列\\t,\\n,\\r和\\\\；\n",
    "* 其他字节的值，使用16进制转义序列。\n",
    "\n",
    "`str`类型的大部分方法都支持`bytes`和`bytearray`类型。\n",
    "* 可用：`endswith`，`replace`，`strip`，`translate`和`upper`等；编译自二进制序列的正则表达式。\n",
    "* 不可用：除了格式化方法（`format`和`format_map`）和几个处理Unicode数据的方法，比如`casefold`，`isdecimal`，`isidentifier`，`isnumeric`，`isprintable`和`encode`）。\n",
    "\n",
    "二进制序列有而`str`没有的方法：`fromhex`，解析十六进制数字对，构建二进制序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'1K\\xce\\xa9'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes.fromhex('314BCEA9')\n",
    "bytes.fromhex('31 4B CE A9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bytes`或`bytearray`实例的构造方法可以传入以下参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import array\n",
    "from random import random\n",
    "\n",
    "a = bytes('hello', encoding='utf8') # 一个str对象和一个encoding关键字参数\n",
    "b = bytes([2, 9, 255, 187]) # 一个可迭代对象，提供0-255之间的数值\n",
    "c = bytes(5) # 一个整数，使用空字节创建对应长度的二进制序列\n",
    "# 一个实现了缓冲协议的对象，比如bytes，bytearray，memoryview，array.array\n",
    "d = bytes(array.array('h', range(5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x02\\t\\xff\\xbb'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x00\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('h', [0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.array('h', range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用缓冲类对象创建`bytes`或`bytearray`时，始终复制源对象中的字节序列，而`memoryview`对象允许在二进制数据结构之间共享内存。\n",
    "### 结构体和内存视图\n",
    "`struct`模块：提供函数解决字节序列和数据之间的转换，即字节序列转换成不同类型字段组成的元组，或者相反。该模块能处理`bytes`，`bytearray`和`memoryview`。\n",
    "\n",
    "`memoryview`对象的切片是一个新的`memoryview`对象，而不会复制字节序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'GIF89a\\x90\\x01\\x90\\x01'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import struct\n",
    "fmt = '<3s3sHH'\n",
    "with open('cat.gif', 'rb') as fp:\n",
    "    img = fp.read()\n",
    "    img_memv = memoryview(img)\n",
    "img[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'GIF89a\\x90\\x01\\x90\\x01'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = img_memv[:10]\n",
    "bytes(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'GIF', b'89a', 400, 400)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct.unpack(fmt, header) # 使用memoryview和struct查看一个gif图像的宽度和高度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "del header\n",
    "del img_memv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 基本的编解码器\n",
    "Python自带超100种编解码器(codec, encoder/decoder)，用于文本和字节序列互相转换。每个`codec`有一个名称，比如`'utf_8'`，且常有别名，比如`'utf8'`，`'utf-8'`和`'U8'`。这些名称可以传给`open()`, `str.encode()`, `bytes.decode()`等函数作为`encoding`参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin_1\tb'El Ni\\xf1o'\n",
      "utf_8\tb'El Ni\\xc3\\xb1o'\n",
      "utf_16\tb'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00'\n"
     ]
    }
   ],
   "source": [
    "# 使用3个编解码器编码字符串El Niño\n",
    "for codec in ['latin_1', 'utf_8', 'utf_16']: # latin-1即扩展ASCII，256个字符\n",
    "    print(codec, 'El Niño'.encode(codec), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 了解编解码问题\n",
    "* `UnicodeEncodeError`：把字符串转换成二进制序列时\n",
    "* `UnicodeDecodeError`：把二进制序列转换成字符串时\n",
    "* `SyntaxError`：如果源码的编码与预期不符\n",
    "\n",
    "### 4.4.1 处理`UnicodeEncodeError`\n",
    "多数非`Unicode`编解码器只能处理`Unicode`字符的一小部分子集。在`encode`时，如果目标编码中没有定义某个字符，会抛出`UnicodeEncodeError`错误。\n",
    "> 编解码器的错误处理方式是可拓展的，可以为`errors`参数注册额外的字符串，方法是把一个名称和一个错误处理函数传给`codecs.register_error`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'S\\xc3\\xa3o Paulo'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 编码成字节序列：成功和错误处理\n",
    "city = 'São Paulo'\n",
    "city.encode('utf_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xff\\xfeS\\x00\\xe3\\x00o\\x00 \\x00P\\x00a\\x00u\\x00l\\x00o\\x00'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city.encode('utf_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'S\\xe3o Paulo'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city.encode('iso8859_1') # latin_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\xe3' in position 1: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-064a572fd5b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cp437'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/encodings/cp437.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, input, errors)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\xe3' in position 1: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "city.encode('cp437')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'So Paulo'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city.encode('cp437', errors='ignore') # IBM PC最初的字符集，包含框图符号，与后来出现的latin1不兼容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'S?o Paulo'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city.encode('cp437', errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'S&#227;o Paulo'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city.encode('cp437', errors='xmlcharrefreplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 处理`UnicodeDecodeError`\n",
    "1. 如果字节序列没有对应的ASCII字符或UTF-8/UTF-16字符，会抛出`UnicodeDecodeError`；\n",
    "2. 一些老式8位编码——`cp1252`, `iso8859_1`和`koi8_r`等——能解码任何字节序列流而不报错。\n",
    "\n",
    "> 乱码字符称为鬼符(gremlin)或mojibake（“变形文本的“的日文）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Montréal'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octets = b'Montr\\xe9al' # Latin1编码的\n",
    "octets.decode('latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montréal\n",
      "Montrιal\n",
      "MontrИal\n"
     ]
    }
   ],
   "source": [
    "print(octets.decode('cp1252'))\n",
    "print(octets.decode('iso8859_7')) # 编码希腊文的\n",
    "print(octets.decode('koi8_r')) # 编码俄文的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-817cdcc4974a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moctets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "octets.decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Montr�al'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octets.decode('utf8', errors='replace') # \\xe9被替换成了U+FFFD，这是官方指定的替换字符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 使用预期之外的编码加载模块时抛出的`SyntaxError`\n",
    "Python3默认使用UTF-8编码源码，Python2则是ASCII编码。如果加载的.py模块中存在非UTF-8字符，且没有事先说明编码，会报错。\n",
    "\n",
    "GNU/LINUX和OS X系统大都使用UTF-8。\n",
    "\n",
    "可以在文件开头声明:\n",
    "> \\# coding: cp1252\n",
    "\n",
    "源码中能不能使用非ASCII字符？源码的目的是便于目标群体阅读和编辑，而不是“所有人”。所以特定情况下，允许使用非ASCII字符，比如当地语言文字。\n",
    "\n",
    "### 4.4.4 如何找出字节序列的编码？\n",
    "不能。除非有人告诉你。\n",
    "\n",
    "某些字节流包含大于127的字节值，我们可以确信其不是ASCII编码，但无法100\\%确定二进制文件的编码是ASCII或UTF-8。\n",
    "\n",
    "统一字符编码侦测包：Chardet，是一个Python库，也提供了命令行工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'ascii', 'confidence': 1.0, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "with open('./floats.txt', 'rb') as fb: # 如果打开方式不是b，则报错\n",
    "    print(chardet.detect(fb.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "with open('./chapter1_python数据模型.ipynb', 'rb') as fb: # 如果打开方式不是b，则报错\n",
    "    print(chardet.detect(fb.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二进制序列编码文本通常不会明确指明自己的编码，但UTF-8格式可以在文本内容的开头添加一个字节序标记。\n",
    "\n",
    "### 4.4.5 BOM：有用的鬼符\n",
    "BOM - 字节序标记`byte-order mark`。\n",
    "\n",
    "字节序分大字节序（big endian）和小字节序（little endian），后者指各个码位的最低有效字节在前，所以字节序只影响一个字符占多个字节的编码.\n",
    "\n",
    "UTF-8不需要BOM，因为它只用一个字节，无所谓高位低位，其U+FEFF字符是一个三字节序列：b'\\xef\\xbb\\xbf'（不过Python不会因为该开头便自动假定文件使用的是UTF-8编码）。\n",
    "\n",
    "UTF-16编码有两个变种，UTF-16LE和UTF-16BE，为区分需要在文本前加上特殊的不可见字符ZERO WIDTH NO-BREAK SPACE (U+FEFF)，在小字节序中为`b'\\xff\\xfe'`（十进制数255，254），这就是BOM。\n",
    "\n",
    "根据标准，如果文件使用UTF-16编码但没有BOM，默认是BE，但Intel x86架构使用的是LE，所以很多文件用的是不带BOM的UTF-16LE。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'E\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00' <class 'bytes'>\n",
      "[69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]\n"
     ]
    }
   ],
   "source": [
    "u16le = 'El Niño'.encode('utf_16le')\n",
    "print(u16le, type(u16le))\n",
    "print(list(u16le))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111]\n"
     ]
    }
   ],
   "source": [
    "u16be = 'El Niño'.encode('utf_16be')\n",
    "print(list(u16be))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 处理文本文件\n",
    "处理文本的最佳实践是Unicode三明治：\n",
    "* 尽早把输入的字节序列解码为字符串(`bytes`->`str`)\n",
    "* 100%处理字符串，处理过程中不解码/编码\n",
    "* 尽晚把输出的字符串编码成字节序列(`str`->`bytes`)\n",
    "\n",
    "Python的`open()`函数会在读取文件时作必要的解码，以文本模式写入文件时还会做必要的编码，所以调用`my_file.read()`方法得到的（已经解码过了）和传给`my_file.write()`方法的都是`str`对象。\n",
    "\n",
    "如果依赖默认编码可能会出问题，以下示例OS X不会报错，因为其`open`的默认编码方式是utf-8。但需要在多台设备或者多种场合下运行的代码，一定不能依赖默认编码，始终明确传入encoding参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('cafe.txt', 'w', encoding='utf8').write('café')\n",
    "open('cafe.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继续上例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='cafe.txt' mode='w' encoding='utf8'>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = open('cafe.txt', 'w', encoding='utf8')\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.write('café') # 返回写入的unicode字符数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.stat('cafe.txt').st_size # utf8中é是两个字节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedReader name='cafe.txt'>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp2 = open('cafe.txt', 'rb')\n",
    "fp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'caf\\xc3\\xa9'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp2.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 除非想判断编码，否则不要再二进制模式中打开__文本文件__；即便如此，也应该使用Chardet，而不是重新发明轮子。常规代码应该只是用二进制模式打开二进制文件。\n",
    "\n",
    "### 编码默认值：一团糟\n",
    "编码的默认设置有许多来源。\n",
    "\n",
    "最好不要依赖默认值。遵从Unicode三明治的建议，而且始终在程序中显式制定编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() -> UTF-8\n",
      "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding -> UTF-8\n",
      "           sys.stdout.isatty() -> False\n",
      "           sys.stdout.encoding -> UTF-8\n",
      "            sys.stdin.isatty() -> False\n",
      "            sys.stdin.encoding -> UTF-8\n",
      "           sys.stderr.isatty() -> False\n",
      "           sys.stderr.encoding -> UTF-8\n",
      "      sys.getdefaultencoding() -> utf-8\n",
      "   sys.getfilesystemencoding() -> utf-8\n"
     ]
    }
   ],
   "source": [
    "expressions = \"\"\"\n",
    "    locale.getpreferredencoding()\n",
    "    type(my_file)\n",
    "    my_file.encoding\n",
    "    sys.stdout.isatty() # 在notebook中为False\n",
    "    sys.stdout.encoding\n",
    "    sys.stdin.isatty()\n",
    "    sys.stdin.encoding\n",
    "    sys.stderr.isatty()\n",
    "    sys.stderr.encoding\n",
    "    sys.getdefaultencoding()\n",
    "    sys.getfilesystemencoding()\n",
    "\"\"\"\n",
    "\n",
    "my_file = open('dummy', 'w')\n",
    "for expression in expressions.split():\n",
    "    value = eval(expression)\n",
    "    print(expression.rjust(30), '->', value)\n",
    "\n",
    "# my_file.encoding文本文件默认使用locale.getpreferredencoding\n",
    "# isatty: 检测文件是否连接到一个终端设备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`locale.getpreferredencoding`返回的编码是最重要的：这是打开文本文件的编码，也是重定向到文件的`sys.stdin/stdout/stderr`的默认编码。\n",
    "\n",
    "`sys.getfefaultencoidng()`用于Python在二进制数据和字符之间转换，这个设置用户不能修改。\n",
    "\n",
    "`sys.getfilesystemencoding()`用于编解码文件名（不是文件内容），比如`open()`处理传入的字符串参数时。\n",
    "\n",
    "## 4.6 为了正确比较而规范化Unicode字符串\n",
    "该问题对于ASCII世界来说很简单，但对于Unicode来说很复杂。\n",
    "\n",
    "因为Unicode有组合字符（变音符号和附加到前一个字符上的记号），打印时作为一个整体，所以字符串表示起来很复杂。\n",
    "例如，'café'有两种表示方法，在之前的Python版本中，两种方式分别有4/5个码位。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "café café\n"
     ]
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301' \n",
    "print(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n"
     ]
    }
   ],
   "source": [
    "print(len(s1), len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 == s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U+0301是COMBINING ACUTE ACCENT，加在e后面得到é。在Unicode标准中，以上两种序列是标准等价物（canonical equivalent），应用程序把它们视作相同的字符。但是Python（可能是原先的版本）看到的是不同的码位序列，因此判定不相等。\n",
    "\n",
    "解决方案是`unicodedata.normalize`函数提供的Unicode规范化，这个函数的第一个参数有4个可选的值：\n",
    "* `NFC`: Normalized Form C, 使用最少的码位构成等价的字符串。\n",
    "* `NFD`: 把组合字符分解成基字符和单独的组合字符。\n",
    "* `NFKC`/`NFKD`: K表示compatibality兼容性。因为Unicode的目标虽然是为各个字符提供规范的码位，但是为了兼容现有的标准，有些字符会出现多次。这两种形式会将各个兼容字符替换成一个或多个兼容分解的字符，有格式损失，但可以为搜索和索引提供便利的中间表述，注意不要用于持久存储。\n",
    "\n",
    "西方键盘通常能输出组合字符，所以用户输入的文本默认是NFC形式。不过安全起见最好使用`normalize('NFC', user_text)`清洗文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "len(s1), len(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalize('NFC', s1)), len(normalize('NFC', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalize('NFD', s2)), len(normalize('NFD', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 == s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFC', s1) == normalize('NFC', s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFD', s1) == normalize('NFC', s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用NFC的时候，有些字符会被规范成另一个字符。例如电阻的单位欧姆Ω会被规范成希腊字母大写的欧米伽，两个字符在视觉上时一样的，但是比较时并不相等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ω Ω\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "ohm = '\\u2126'\n",
    "ohm_c = normalize('NFC', ohm)\n",
    "print(ohm, ohm_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('OHM SIGN', 'GREEK CAPITAL LETTER OMEGA')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name(ohm), name(ohm_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohm == ohm_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFC', ohm) == normalize('NFC', ohm_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NFKC`/`NFKD`在兼容字符上的实践。\n",
    "\n",
    "比如希腊字母表中已有μ（码位是U+03BC），但Unicode还是添加了微符号μ（U+00B5），以便与latin1相互转换，因此微符号是兼容字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'½'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "half = '\\u00BD'\n",
    "half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1⁄2'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFKC', half) # 如果搜索1/2还能搜索到'½'，那是很好的，所以NFKC等是有用的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('µ', 'μ')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro = '\\u00B5'\n",
    "micro_kc = normalize('NFKC', micro)\n",
    "micro, micro_kc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 956)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(micro), ord(micro_kc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MICRO SIGN', 'GREEK SMALL LETTER MU')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name(micro), name(micro_kc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.1 大小写折叠\n",
    "为搜索和索引准备文本时很有用的一个操作，即把所有文本变成小写，再做其他转换，`str.casefold()`方法支持。\n",
    "\n",
    "对于只包含latin1的文本，`casefold()`的结果和`lower()`一样，除了以下两个例外："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "µ μ\n",
      "MICRO SIGN , GREEK SMALL LETTER MU\n"
     ]
    }
   ],
   "source": [
    "micro = 'µ'\n",
    "micro_cf = micro.casefold()\n",
    "print(micro, micro_cf)\n",
    "print(name(micro), ',', name(micro_cf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ß ss\n",
      "LATIN SMALL LETTER SHARP S\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "eszett = 'ß'\n",
    "eszett_cf = eszett.casefold()\n",
    "print(eszett, eszett_cf)\n",
    "print(name(eszett))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与Unicode相关的任何问题一样，大小写折叠复杂，有许多语言上的特殊情况，但是Python核心团队尽力提供了一种方案，能满足大多数用户的需求。\n",
    "\n",
    "### 4.6.2 规范化文本匹配实用函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对大多数应用来说，NFC是最好的规范方式。不去分大小写的比较应该使用`casefold()`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for normalized Unicode string comparison\n",
    "from unicodedata import normalize\n",
    "\n",
    "# using NPC, case sensitive\n",
    "def nfc_equal(s1, s2):\n",
    "    return normalize('NFC', s1) == normalize('NFC', s2)\n",
    "\n",
    "# using NFC with case folding\n",
    "def fold_equal(s1, s2):\n",
    "    return normalize('NFC', s1).casefold() == normalize('NFC', s2).casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "s3 = 'cafe\\u0301'\n",
    "s1 == s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfc_equal(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_equal(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = 'Straße'\n",
    "s4 = 'Strasse'\n",
    "s3 == s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfc_equal(s3, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_equal(s3, s4) # 因为用了casefold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfc_equal('A', 'a'), fold_equal('A', 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.3 极端“规范化”：去掉变音符号\n",
    "Google搜索涉及很多技术，其一显然是忽略变音符号（如重音符、下加符等）。去掉变音符号不是正确的规范方式，但是现实生活中却很有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉全部变音符号的函数\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"去掉全部变音符号\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))\n",
    "    return unicodedata.normalize('NFC', shaved) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cafe'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "shave_marks(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.combining(normalize('NFC', 'é'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 230)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.combining(normalize('NFD', 'é')[0]), unicodedata.combining(normalize('NFD', 'é')[1]) \n",
    "# 0: no combining class\n",
    "# 注意：NFD拆开后是基字符在前，组合字符在后"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的`shave_marks`函数做得太多了，通常去掉变音符号是为了让拉丁文本变成纯粹的ASCII，但是该函数还会修改希腊字母，但是去掉变音符号并不能让它们变成ASCII字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shave_marks_latin(txt):\n",
    "    \"\"\"把拉丁基字符中的所有变音符号删除\"\"\"\n",
    "    norm_txt = normalize('NFD', txt)\n",
    "    latin_base = False\n",
    "    keepers = []\n",
    "    \n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:\n",
    "            continue # 不保留latin字母的组合字符\n",
    "        keepers.append(c)\n",
    "        # 如果不是组合字符，则为新的基字符\n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in string.ascii_letters\n",
    "    return normalize('NFC', ''.join(keepers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ωμεγα\n",
      "ὦμέγα\n"
     ]
    }
   ],
   "source": [
    "greek = 'ὦμέγα'\n",
    "print(shave_marks(greek))\n",
    "print(shave_marks_latin(greek))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更彻底的规范化是把西文文本中的常见符号（如弯折号、长破折号、项目符号等）替换成ASCII中的对等字符。对应函数见书中，使用的是`str.maketrans()`和`translate()`函数。\n",
    "\n",
    "注意以上标准化操作需要考虑到目标语言中变音符号的使用规则和转换后的用途等。\n",
    "\n",
    "## 4.7 Unicode文本排序\n",
    "Python比较任何类型的序列时，会一一比较序列内的元素，比如字符串比较的是码位。但是对于___非ASCII字符___，结果不尽如人意，主要涉及到变音符号对排序的影响。\n",
    "\n",
    "Python中非ASCII字符的标准排序方式是使用`locale.strxfrm`函数，可以自己设置地区，这个设置是全局的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = ['caju', 'atemoia', '', 'açaí']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import locale\n",
    "# locale.setlocale(locale.LC_COLLATE, 'zh_CN.UTF-8')\n",
    "# fruits = []\n",
    "# sorted(fruits, key=locale.strxfrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准库的方案可用，但对不同操作系统的支持不够友好，还依赖区域设置，可以用PyPI中的PyUCA（Unicode Collation Algorithm）库。\n",
    "#### 使用Unicode排序算法排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 补充知识：字符串的一些方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'HeLLo'\n",
    "s.casefold() # 全部转小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('MyPy'.isidentifier()) # 是否是有效标识符，只含字母数字和下划线，不含空格，不以数字开头\n",
    "print('__init__'.isidentifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.isprintable()) # 换行\n",
    "print('\\t'.isprintable()) # 制表\n",
    "print('\\r'.isprintable()) # 回车\n",
    "print('\\\\'.isprintable())\n",
    "print('hello'.isprintable())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th3s 3s str3ng 2x1mpl2...w4w!!!\n"
     ]
    }
   ],
   "source": [
    "intab = 'aeiou'\n",
    "outtab = '12345'\n",
    "trantab = str.maketrans(intab, outtab)  # 制作翻译表\n",
    "s = 'this is string example...wow!!!'\n",
    "print (s.translate(trantab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 补充知识：`isdigit()`, `isdecimal()`, `isnumeric()`\n",
    ">`isdigit()`\n",
    "* True: Unicode数字，全角数字（双字节），___byte数字（单字节）___\n",
    "* False: 汉字数字，小数\n",
    "* Error: 无 \n",
    "\n",
    ">`isdecimal()`\n",
    "* True: Unicode数字，全角数字（双字节）\n",
    "* False: 汉字数字,小数\n",
    "* Error: byte数字（单字节） \n",
    "\n",
    ">`isnumeric()`\n",
    "* True: Unicode数字，全角数字（双字节），汉字数字 \n",
    "* False: 小数 \n",
    "* Error: byte数字（单字节）\n",
    "\n",
    "亲测`isnumeric()`并不支持罗马数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "               \n",
      "True\n",
      "True\n",
      "True\n",
      "               \n",
      "True\n",
      "               \n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "num = \"1\"#unicode\n",
    "print(num.isdigit()) # True\n",
    "print(num.isdecimal()) # True\n",
    "print(num.isnumeric()) # True\n",
    "print(' ' * 15)\n",
    "num = \"1\"# 全角\n",
    "print(num.isdigit()) # True\n",
    "print(num.isdecimal()) # True\n",
    "print(num.isnumeric()) # True\n",
    "print(' ' * 15)\n",
    "num = b\"1\"# byte\n",
    "print(num.isdigit()) # True\n",
    "# print(num.isdecimal()) # AttributeError ‘bytes’ object has no attribute ‘isdecimal’\n",
    "# print(num.isnumeric()) # AttributeError ‘bytes’ object has no attribute ‘isnumeric’\n",
    "print(' ' * 15)\n",
    "num = \"四\"# 汉字\n",
    "print(num.isdigit()) # False\n",
    "print(num.isdecimal()) # False\n",
    "print(num.isnumeric()) # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# isnumetic检查文本中所有字符是否都是数字，可以是其他进制，可以是其他语言，比如中文\n",
    "a = \"\\u0030\" #unicode for 0\n",
    "b = \"\\u00B2\" #unicode for ²\n",
    "c = \"10km2\"\n",
    "d = \"-1\"\n",
    "e = \"1.5\"\n",
    "\n",
    "print(a.isnumeric())\n",
    "print(b.isnumeric())\n",
    "print(c.isnumeric())\n",
    "print(d.isnumeric())\n",
    "print(e.isnumeric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 检查unicode对象中的所有字符是否都是十进制数，即全部属于0-9\n",
    "print('abc'.isdecimal())\n",
    "print('10'.isdecimal())\n",
    "\n",
    "print(\"\\u0030\".isdecimal())\n",
    "print(\"\\u00B2\".isdecimal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 16: 'l'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-8c37d10fc973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 16: 'l'"
     ]
    }
   ],
   "source": [
    "int('l', base=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.011px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
